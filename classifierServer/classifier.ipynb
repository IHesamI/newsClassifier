{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150096 entries, 0 to 150095\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  150096 non-null  int64 \n",
      " 1   Text        150096 non-null  object\n",
      " 2   Category    150096 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Science and Culture', 'Sport', 'Economy',\n",
       "       'Miscellaneous.World News', 'Miscellaneous.Urban', 'Social.Women',\n",
       "       'Social', 'Literature and Art', 'Politics', 'Miscellaneous',\n",
       "       'Economy.Bank and Bourse', 'Politics.Iran Politics', 'Tourism',\n",
       "       'Social.Religion', 'Miscellaneous.Picture',\n",
       "       'Miscellaneous.Happenings', 'Science and Culture.Science.Book',\n",
       "       'Literature and Art.Art', 'Miscellaneous.Islamic Councils',\n",
       "       'Literature and Art.Art.Cinema',\n",
       "       'Science and Culture.Science.Information and Communication Technology',\n",
       "       'Economy.Oil', 'Economy.Commerce', 'Natural Environment',\n",
       "       'Science and Culture.Science', 'Economy.Industry',\n",
       "       'Economy.Agriculture', 'Sport.World Cup',\n",
       "       'Miscellaneous.Picture.Caricature', 'Literature and Art.Art.Music',\n",
       "       'Literature and Art.Art.Theater',\n",
       "       'Economy.Dwelling and Construction',\n",
       "       'Science and Culture.Science.Medicine and Remedy',\n",
       "       'Literature and Art.Literature'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...\n",
       "1    \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...\n",
       "2    \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...\n",
       "3    \\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...\n",
       "4    \\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Science and Culture\n",
       "1                       Sport\n",
       "2                     Economy\n",
       "3    Miscellaneous.World News\n",
       "4                       Sport\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopWordsFile = open('./persian-stopwords/persian')\n",
    "# stopWords = stopWordsFile.read().splitlines()\n",
    "train_df['Text'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopWords]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df['Text'].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...\n",
       "1    \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...\n",
       "2    \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...\n",
       "3    \\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...\n",
       "4    \\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "X_train = X_train.apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(to_replace=r'[^\\w\\s]', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(to_replace=r'\\d', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize\n",
    "# converting each sentence to list of words and inserting in sents\n",
    "X_train = X_train.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [خبرنامه, دانشگاه, علم, و, صنعت, ايران, شماره,...\n",
       "1    [تا, پايان, سال, دهها, زمين, فوتبال, و, سالن, ...\n",
       "2    [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3    [كرتين, براي, سومين, بار, نخست, وزير, كانادا, ...\n",
       "4    [خداحافظ, رفقا, نمايندگان, اروپاي, شرقي, در, ج...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile = open('./stopwords.dat')\n",
    "stopWordsFile2 = open('./persian-stopwords/persian')\n",
    "combined=stopWordsFile.read().split('\\n') + stopWordsFile2.read().split('\\n')\n",
    "stopWords= set(combined)\n",
    "X_train = X_train.apply(lambda x: [word for word in x if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1    [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2    [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3    [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4    [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=10, window=5,seed=42, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('غير', 0.8945706486701965),\n",
       " ('متعلق', 0.8168612122535706),\n",
       " ('مختص', 0.8097556233406067),\n",
       " ('محل', 0.8038725852966309),\n",
       " ('نخستين', 0.7865356206893921),\n",
       " ('ترتيب', 0.7630936503410339),\n",
       " ('زد', 0.7480353713035583),\n",
       " ('هايش', 0.724714457988739),\n",
       " ('سرماي', 0.7185304760932922),\n",
       " ('اسلاف', 0.7165913581848145)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('فوتبال',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorize(sentence) for sentence in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
