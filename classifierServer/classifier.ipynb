{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150096 entries, 0 to 150095\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  150096 non-null  int64 \n",
      " 1   Text        150096 non-null  object\n",
      " 2   Category    150096 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Science and Culture', 'Sport', 'Economy',\n",
       "       'Miscellaneous.World News', 'Miscellaneous.Urban', 'Social.Women',\n",
       "       'Social', 'Literature and Art', 'Politics', 'Miscellaneous',\n",
       "       'Economy.Bank and Bourse', 'Politics.Iran Politics', 'Tourism',\n",
       "       'Social.Religion', 'Miscellaneous.Picture',\n",
       "       'Miscellaneous.Happenings', 'Science and Culture.Science.Book',\n",
       "       'Literature and Art.Art', 'Miscellaneous.Islamic Councils',\n",
       "       'Literature and Art.Art.Cinema',\n",
       "       'Science and Culture.Science.Information and Communication Technology',\n",
       "       'Economy.Oil', 'Economy.Commerce', 'Natural Environment',\n",
       "       'Science and Culture.Science', 'Economy.Industry',\n",
       "       'Economy.Agriculture', 'Sport.World Cup',\n",
       "       'Miscellaneous.Picture.Caricature', 'Literature and Art.Art.Music',\n",
       "       'Literature and Art.Art.Theater',\n",
       "       'Economy.Dwelling and Construction',\n",
       "       'Science and Culture.Science.Medicine and Remedy',\n",
       "       'Literature and Art.Literature'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...\n",
       "1    \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...\n",
       "2    \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...\n",
       "3    \\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...\n",
       "4    \\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Science and Culture\n",
       "1                       Sport\n",
       "2                     Economy\n",
       "3    Miscellaneous.World News\n",
       "4                       Sport\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopWordsFile = open('./persian-stopwords/persian')\n",
    "# stopWords = stopWordsFile.read().splitlines()\n",
    "train_df['Text'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopWords]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df['Text'].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...\n",
       "1      \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...\n",
       "2      \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...\n",
       "3      \\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...\n",
       "4      \\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...\n",
       "                             ...                        \n",
       "495    \\nپيامدهاي حمله ياقوت كبود به اينترنت \\nبا گذش...\n",
       "496    \\nطرح مميزي املاك و پيمايش خانه به خانه \\nدر ا...\n",
       "497    \\nگل و گياه زعفران بهاره \\nنام علمي: Vernus Cr...\n",
       "498    \\nروز گذشته با صدور يك بيانيه اعلام \\nاظهار نگ...\n",
       "499    \\nبرگزاري كنكور آزمايشي \\nخانه فرهنگ ابوذر برا...\n",
       "Name: Text, Length: 500, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "X_train = X_train.apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(to_replace=r'[^\\w\\s]', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(to_replace=r'\\d', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize\n",
    "# converting each sentence to list of words and inserting in sents\n",
    "X_train = X_train.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [خبرنامه, دانشگاه, علم, و, صنعت, ايران, شماره,...\n",
       "1      [تا, پايان, سال, دهها, زمين, فوتبال, و, سالن, ...\n",
       "2      [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3      [كرتين, براي, سومين, بار, نخست, وزير, كانادا, ...\n",
       "4      [خداحافظ, رفقا, نمايندگان, اروپاي, شرقي, در, ج...\n",
       "                             ...                        \n",
       "495    [پيامدهاي, حمله, ياقوت, كبود, به, اينترنت, با,...\n",
       "496    [طرح, مميزي, املاك, و, پيمايش, خانه, به, خانه,...\n",
       "497    [گل, و, گياه, زعفران, بهاره, نام, علمي, Vernus...\n",
       "498    [روز, گذشته, با, صدور, يك, بيانيه, اعلام, اظها...\n",
       "499    [برگزاري, كنكور, آزمايشي, خانه, فرهنگ, ابوذر, ...\n",
       "Name: Text, Length: 500, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile = open('./stopwords.dat')\n",
    "stopWordsFile2 = open('./persian-stopwords/persian')\n",
    "combined=stopWordsFile.read().split('\\n') + stopWordsFile2.read().split('\\n')\n",
    "stopWords= set(combined)\n",
    "X_train = X_train.apply(lambda x: [word for word in x if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1      [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2      [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3      [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4      [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "                             ...                        \n",
       "495    [پيامدهاي, حمله, ياقوت, كبود, اينترنت, گذشت, ي...\n",
       "496    [طرح, مميزي, املاك, پيمايش, خانه, خانه, استان,...\n",
       "497    [گل, گياه, زعفران, بهاره, علمي, Vernus, Crocus...\n",
       "498    [صدور, يك, بيانيه, اظهار, نگراني, عميق, جمعيت,...\n",
       "499    [برگزاري, كنكور, آزمايشي, خانه, فرهنگ, ابوذر, ...\n",
       "Name: Text, Length: 500, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=50, window=5,seed=42, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('حوزه', 0.9990984201431274),\n",
       " ('جريان', 0.9990294575691223),\n",
       " ('سوي', 0.9990288615226746),\n",
       " ('طريق', 0.998964250087738),\n",
       " ('تبديل', 0.998918890953064),\n",
       " ('جلوگيري', 0.9989074468612671),\n",
       " ('آمريكايي', 0.9989061951637268),\n",
       " ('ديدگاه', 0.998863697052002),\n",
       " ('منافع', 0.9988560676574707),\n",
       " ('شهروندان', 0.9988560080528259)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('اقتصاد',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorize(sentence) for sentence in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
