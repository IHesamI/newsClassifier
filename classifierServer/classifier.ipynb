{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cluster_mapping = {\n",
    "    \"economic\": [\n",
    "        'Economy',\n",
    "        'Economy.Bank and Bourse',\n",
    "        'Economy.Oil',\n",
    "        'Economy.Commerce',\n",
    "        'Economy.Industry',\n",
    "        'Economy.Agriculture',\n",
    "        'Economy.Dwelling and Construction'\n",
    "    ],\n",
    "    \"cultural and artistic\": [\n",
    "        'Science and Culture',\n",
    "        'Science and Culture.Science.Book',\n",
    "        'Literature and Art',\n",
    "        'Literature and Art.Art',\n",
    "        'Literature and Art.Art.Cinema',\n",
    "        'Literature and Art.Art.Music',\n",
    "        'Literature and Art.Art.Theater',\n",
    "        'Science and Culture.Science',\n",
    "        'Science and Culture.Science.Medicine and Remedy',\n",
    "        'Literature and Art.Literature'\n",
    "    ],\n",
    "    \"political\": [\n",
    "        'Politics',\n",
    "        'Politics.Iran Politics'\n",
    "    ],\n",
    "    \"technological\": [\n",
    "        'Science and Culture.Science.Information and Communication Technology'\n",
    "    ],\n",
    "    \"sports\": [\n",
    "        'Sport',\n",
    "        'Sport.World Cup'\n",
    "    ],\n",
    "    \"social\": [\n",
    "        'Social',\n",
    "        'Social.Women',\n",
    "        'Social.Religion'\n",
    "    ],\n",
    "    \"miscellaneous\": [\n",
    "        'Miscellaneous',\n",
    "        'Miscellaneous.World News',\n",
    "        'Miscellaneous.Urban',\n",
    "        'Miscellaneous.Picture',\n",
    "        'Miscellaneous.Happenings',\n",
    "        'Miscellaneous.Islamic Councils',\n",
    "        'Miscellaneous.Picture.Caricature'\n",
    "    ],\n",
    "    \"tourism\": [\n",
    "        'Tourism'\n",
    "    ],\n",
    "    \"environment\": [\n",
    "        'Natural Environment'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def categoesMapping(cat):\n",
    "    for key,value in topic_cluster_mapping.items():\n",
    "        if cat in value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categiesdData=train_df['Category'].apply(categoesMapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         cultural and artistic\n",
       "1                        sports\n",
       "2                      economic\n",
       "3                 miscellaneous\n",
       "4                        sports\n",
       "                  ...          \n",
       "150091            miscellaneous\n",
       "150092            miscellaneous\n",
       "150093            miscellaneous\n",
       "150094    cultural and artistic\n",
       "150095                political\n",
       "Name: Category, Length: 150096, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categiesdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows  \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "categiesdData= label_encoder.fit_transform(categiesdData) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "train_df['Text'] = train_df['Text'].apply(remove_urls)\n",
    "\n",
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "\n",
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'\\d', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'\\n', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData=train_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize\n",
    "# converting each sentence to list of words and inserting in sents\n",
    "processedData= processedData.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [خبرنامه, دانشگاه, علم, و, صنعت, ايران, شماره,...\n",
       "1    [تا, پايان, سال, دهها, زمين, فوتبال, و, سالن, ...\n",
       "2    [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3    [كرتين, براي, سومين, بار, نخست, وزير, كانادا, ...\n",
       "4    [خداحافظ, رفقا, نمايندگان, اروپاي, شرقي, در, ج...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processedData).to_csv('processedText.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile = open('./stopwords.dat')\n",
    "stopWordsFile2 = open('./persian-stopwords/persian')\n",
    "combined=stopWordsFile.read().split('\\n') + stopWordsFile2.read().split('\\n')\n",
    "stopWords= set(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData=processedData.apply(lambda x: [word for word in x if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processedData).to_csv('finalTexts.csv',header=None,index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finalTexts.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1         [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2         [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3         [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4         [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "                                ...                        \n",
       "150091    [مشكل, سدسازي, وزير, نيرو, كشور, كمبود, اعتبار...\n",
       "150092    [خودسوزي, يك, هوادار, ك, ك, شهر, دياربكر, تركي...\n",
       "150093    [نيمه, سال, جاري, دستگاه, اتوبوس, كارت, بليت, ...\n",
       "150094    [كتابخانه, مركز, دانشگاه, تهران, دانشكده, هنره...\n",
       "150095    [پيام, رئيس, جمهوري, سران, كشورهاي, عضو, سازما...\n",
       "Name: 0, Length: 150096, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=df[0].apply(lambda text : eval(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , x_test ,y_train ,y_test = train_test_split(texts,categiesdData,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22210     [نمايش, ويژه, زماني, براي, مستي, اسبها, فيلم, ...\n",
       "41612     [غير, از, ما, انسانهاي, ديگري, هم, در, عالم, ؟...\n",
       "82332     [نقش, قانون, در, مبارزه, با, تبعيض, و, دفاع, ا...\n",
       "30343     [وزير, امور, خارجه, :, حرفه, اي, شدن, برنامه, ...\n",
       "24768     [مبارزه, با, قاچاق, كالا, بايد, از, داخل, كشور...\n",
       "                                ...                        \n",
       "42709     [چريكهاي, زاپاتيستا;, از, جنگل, هاي, لاكاندون,...\n",
       "142397    [رابرتسون, :, سياست, ناتو, بازدارندگي, است, جو...\n",
       "125393    [آزمون, سراسري, كارداني, نظام, جديد, و, مرداد,...\n",
       "130451    [رئيس, سازمان, ايرانگردي, وجهانگردي, اصفهان, :...\n",
       "68499     [براي, جذب, سرمايه, گذاري, خارجي, سرعت, كافي, ...\n",
       "Name: Text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['نمايش',\n",
       "  'ويژه',\n",
       "  'زماني',\n",
       "  'براي',\n",
       "  'مستي',\n",
       "  'اسبها',\n",
       "  'فيلم',\n",
       "  'زماني',\n",
       "  'براي',\n",
       "  'مستي',\n",
       "  'اسبها',\n",
       "  'براي',\n",
       "  'روزنامه',\n",
       "  'نگاران',\n",
       "  'و',\n",
       "  'خانواده',\n",
       "  'هاي',\n",
       "  'آنان',\n",
       "  'نمايش',\n",
       "  'داده',\n",
       "  'مي',\n",
       "  'شود',\n",
       "  '.',\n",
       "  'اين',\n",
       "  'فيلم',\n",
       "  'دوشنبه',\n",
       "  '5',\n",
       "  'دي',\n",
       "  '/',\n",
       "  '20',\n",
       "  '15',\n",
       "  'ساعت',\n",
       "  'در',\n",
       "  'سينما',\n",
       "  'سپيده',\n",
       "  'براي',\n",
       "  'اعضاي',\n",
       "  'انجمن',\n",
       "  'صنفي',\n",
       "  'روزنامه',\n",
       "  'نگاران',\n",
       "  'و',\n",
       "  'خانواده',\n",
       "  'آنان',\n",
       "  'به',\n",
       "  'نمايش',\n",
       "  'درمي',\n",
       "  'آيد',\n",
       "  '.',\n",
       "  'اعضاي',\n",
       "  'متقاضي',\n",
       "  'مي',\n",
       "  'توانند',\n",
       "  'جهت',\n",
       "  'رزرو',\n",
       "  'بليت',\n",
       "  'با',\n",
       "  'شماره',\n",
       "  'هاي',\n",
       "  '8956796',\n",
       "  '8956365',\n",
       "  'و',\n",
       "  'تماس',\n",
       "  'حاصل',\n",
       "  'كنند',\n",
       "  '.',\n",
       "  'گفتني',\n",
       "  'است',\n",
       "  'فيلم',\n",
       "  'زماني',\n",
       "  'براي',\n",
       "  'مستي',\n",
       "  'اسبها',\n",
       "  'به',\n",
       "  'كارگرداني',\n",
       "  'بهمن',\n",
       "  'قبادي',\n",
       "  'برنده',\n",
       "  'دوربين',\n",
       "  'طلايي',\n",
       "  'جشنواره',\n",
       "  'كن',\n",
       "  'امسال',\n",
       "  'بوده_است',\n",
       "  '.']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(X_train[:5000], vector_size=24, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('كنوني', 0.8154117465019226),\n",
       " ('گسترش', 0.7982319593429565),\n",
       " ('كشورهاي', 0.7817534804344177),\n",
       " ('مناسبات', 0.780518651008606),\n",
       " ('تحولات', 0.7683041095733643),\n",
       " ('سياست', 0.7679218649864197),\n",
       " ('توسعه', 0.7613726258277893),\n",
       " ('كشورهايي', 0.7612814903259277),\n",
       " ('پولي', 0.759128212928772),\n",
       " ('تجارت', 0.7515566945075989)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('اقتصاد',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize\n",
    "# converting each sentence to list of words and inserting in sents\n",
    "X_train = X_train.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1       [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2       [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3       [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4       [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "                              ...                        \n",
       "9995    [مسئوليت, شهروندان, رئيس, جمهور, راي, خويش, تي...\n",
       "9996    [مديرمسئول, روزنامه, همبستگي, دادگاه, احضار, گ...\n",
       "9997    [شيرهاي, آب, توجه, موقعيت, بحراني, ذخاير, آب, ...\n",
       "9998    [نيم, رخ, نگاهي, زندگي, جبران, خليل, جبران, پس...\n",
       "9999    [پيروزي, پيكان, مدعي, واليبال, برتر, باشگاههاي...\n",
       "Name: Text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=50, window=5,seed=42, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ليگ', 0.9693446755409241),\n",
       " ('باشگاهي', 0.9688852429389954),\n",
       " ('بازيهاي', 0.9644466042518616),\n",
       " ('قهرماني', 0.9510931372642517),\n",
       " ('تيمهاي', 0.9510273337364197),\n",
       " ('تيمي', 0.9507378339767456),\n",
       " ('رقابتهاي', 0.9420532584190369),\n",
       " ('برتر', 0.9419983625411987),\n",
       " ('بازيكنانش', 0.9363963007926941),\n",
       " ('گيران', 0.9300103187561035)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('اقتصاد',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorize(sentence) for sentence in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
