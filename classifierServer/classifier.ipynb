{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cluster_mapping = {\n",
    "    \"economic\": [\n",
    "        'Economy',\n",
    "        'Economy.Bank and Bourse',\n",
    "        'Economy.Oil',\n",
    "        'Economy.Commerce',\n",
    "        'Economy.Industry',\n",
    "        'Economy.Agriculture',\n",
    "        'Economy.Dwelling and Construction'\n",
    "    ],\n",
    "    \"cultural and artistic\": [\n",
    "        'Science and Culture',\n",
    "        'Science and Culture.Science.Book',\n",
    "        'Literature and Art',\n",
    "        'Literature and Art.Art',\n",
    "        'Literature and Art.Art.Cinema',\n",
    "        'Literature and Art.Art.Music',\n",
    "        'Literature and Art.Art.Theater',\n",
    "        'Science and Culture.Science',\n",
    "        'Science and Culture.Science.Medicine and Remedy',\n",
    "        'Literature and Art.Literature'\n",
    "    ],\n",
    "    \"political\": [\n",
    "        'Politics',\n",
    "        'Politics.Iran Politics'\n",
    "    ],\n",
    "    \"technological\": [\n",
    "        'Science and Culture.Science.Information and Communication Technology'\n",
    "    ],\n",
    "    \"sports\": [\n",
    "        'Sport',\n",
    "        'Sport.World Cup'\n",
    "    ],\n",
    "    \"social\": [\n",
    "        'Social',\n",
    "        'Social.Women',\n",
    "        'Social.Religion'\n",
    "    ],\n",
    "    \"miscellaneous\": [\n",
    "        'Miscellaneous',\n",
    "        'Miscellaneous.World News',\n",
    "        'Miscellaneous.Urban',\n",
    "        'Miscellaneous.Picture',\n",
    "        'Miscellaneous.Happenings',\n",
    "        'Miscellaneous.Islamic Councils',\n",
    "        'Miscellaneous.Picture.Caricature'\n",
    "    ],\n",
    "    \"tourism\": [\n",
    "        'Tourism'\n",
    "    ],\n",
    "    \"environment\": [\n",
    "        'Natural Environment'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def categoesMapping(cat):\n",
    "    for key,value in topic_cluster_mapping.items():\n",
    "        if cat in value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categiesdData=train_df['Category'].apply(categoesMapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         cultural and artistic\n",
       "1                        sports\n",
       "2                      economic\n",
       "3                 miscellaneous\n",
       "4                        sports\n",
       "                  ...          \n",
       "150091            miscellaneous\n",
       "150092            miscellaneous\n",
       "150093            miscellaneous\n",
       "150094    cultural and artistic\n",
       "150095                political\n",
       "Name: Category, Length: 150096, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categiesdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows  \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "categiesdData= label_encoder.fit_transform(categiesdData) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "train_df['Text'] = train_df['Text'].apply(remove_urls)\n",
    "\n",
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "\n",
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'\\d', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = train_df['Text'].replace(to_replace=r'\\n', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData=train_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize\n",
    "# converting each sentence to list of words and inserting in sents\n",
    "processedData= processedData.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [خبرنامه, دانشگاه, علم, و, صنعت, ايران, شماره,...\n",
       "1    [تا, پايان, سال, دهها, زمين, فوتبال, و, سالن, ...\n",
       "2    [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3    [كرتين, براي, سومين, بار, نخست, وزير, كانادا, ...\n",
       "4    [خداحافظ, رفقا, نمايندگان, اروپاي, شرقي, در, ج...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processedData).to_csv('processedText.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile = open('./stopwords.dat')\n",
    "stopWordsFile2 = open('./persian-stopwords/persian')\n",
    "combined=stopWordsFile.read().split('\\n') + stopWordsFile2.read().split('\\n')\n",
    "stopWords= set(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData=processedData.apply(lambda x: [word for word in x if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processedData).to_csv('finalTexts.csv',header=None,index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finalTexts.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1         [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2         [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3         [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4         [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "                                ...                        \n",
       "150091    [مشكل, سدسازي, وزير, نيرو, كشور, كمبود, اعتبار...\n",
       "150092    [خودسوزي, يك, هوادار, ك, ك, شهر, دياربكر, تركي...\n",
       "150093    [نيمه, سال, جاري, دستگاه, اتوبوس, كارت, بليت, ...\n",
       "150094    [كتابخانه, مركز, دانشگاه, تهران, دانشكده, هنره...\n",
       "150095    [پيام, رئيس, جمهوري, سران, كشورهاي, عضو, سازما...\n",
       "Name: 0, Length: 150096, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=df[0].apply(lambda text : eval(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150096,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts.to_csv('textesList.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , x_test ,y_train ,y_test = train_test_split(texts,categiesdData,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTOR_SIZE,ZARP = 50,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(X_train, vector_size=VECTOR_SIZE, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words_vecs = [w2v_model.wv[word] for word in sentence if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(VECTOR_SIZE)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)\n",
    "\n",
    "X_train = np.array([vectorize(sentence) for sentence in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([vectorize(sentence) for sentence in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eniac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=15,min_samples_leaf=5)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictofAccuracyVectorSize = {\n",
    "    {'VECTOR_SIZE': 24,   'Accuracy': 0.724666326145373}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7427048634243838\n",
      "Precision: 0.7346016550281594\n",
      "Recall: 0.7427048634243838\n",
      "F1 score: 0.7339464886130384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy:', accuracy_score(y_test, rfc_y_pred))\n",
    "print('Precision:', precision_score(y_test, rfc_y_pred,average='weighted'))\n",
    "print('Recall:', recall_score(y_test, rfc_y_pred,average='weighted'))\n",
    "print('F1 score:', f1_score(y_test, rfc_y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7427048634243838\n",
      "Precision: 0.7427048634243838\n",
      "Recall: 0.7427048634243838\n",
      "F1 score: 0.7339464886130384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred,average='micro'))\n",
    "print('Recall:', recall_score(y_test, y_pred,average='micro'))\n",
    "print('F1 score:', f1_score(y_test, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [خبرنامه, دانشگاه, علم, صنعت, ايران, شماره, يا...\n",
       "1       [پايان, سال, دهها, زمين, فوتبال, سالن, ورزش, ب...\n",
       "2       [انجمن, توليدكنندگان, تجهيزات, صنعت, نفت, تشكي...\n",
       "3       [كرتين, براي, سومين, وزير, كانادا, ژان, كرتين,...\n",
       "4       [رفقا, نمايندگان, اروپاي, شرقي, جام, بابك, كما...\n",
       "                              ...                        \n",
       "9995    [مسئوليت, شهروندان, رئيس, جمهور, راي, خويش, تي...\n",
       "9996    [مديرمسئول, روزنامه, همبستگي, دادگاه, احضار, گ...\n",
       "9997    [شيرهاي, آب, توجه, موقعيت, بحراني, ذخاير, آب, ...\n",
       "9998    [نيم, رخ, نگاهي, زندگي, جبران, خليل, جبران, پس...\n",
       "9999    [پيروزي, پيكان, مدعي, واليبال, برتر, باشگاههاي...\n",
       "Name: Text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=50, window=5,seed=42, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ليگ', 0.9693446755409241),\n",
       " ('باشگاهي', 0.9688852429389954),\n",
       " ('بازيهاي', 0.9644466042518616),\n",
       " ('قهرماني', 0.9510931372642517),\n",
       " ('تيمهاي', 0.9510273337364197),\n",
       " ('تيمي', 0.9507378339767456),\n",
       " ('رقابتهاي', 0.9420532584190369),\n",
       " ('برتر', 0.9419983625411987),\n",
       " ('بازيكنانش', 0.9363963007926941),\n",
       " ('گيران', 0.9300103187561035)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('اقتصاد',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorize(sentence) for sentence in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
